{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generative Adversarial Networks (GAN) example in PyTorch.\n",
    "# See related blog post at \n",
    "# https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "\n",
    "num_epochs = 3000\n",
    "#num_epochs = 30000\n",
    "print_interval = 200\n",
    "\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "#dtype = torch.FloatTensor\n",
    "\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "#%time\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast).cuda(), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss().cuda()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the networks on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = G.cuda()\n",
    "D = D.cuda()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.8314700126647949/0.7408788800239563 G: 0.6517988443374634 (Real: [3.5847136580944063, 1.3028425320120185], Fake: [-0.19148351490497589, 0.0026327345021920287]) \n",
      "200: D: 0.005149307660758495/0.6713951826095581 G: 0.7198851704597473 (Real: [4.0853431904315949, 1.2638330799754618], Fake: [-0.13201068341732025, 0.012496495198185742]) \n",
      "400: D: 4.4466054532676935e-05/0.4138678014278412 G: 1.1039412021636963 (Real: [3.7992736539244651, 1.45441843807528], Fake: [-0.062396438270807264, 0.042444088267637958]) \n",
      "600: D: 7.271793037944008e-06/0.4078928232192993 G: 0.9893813133239746 (Real: [3.7780758392810823, 1.30437147225858], Fake: [-0.22115120703354477, 0.17351046334565301]) \n",
      "800: D: 0.001397214480675757/0.15718115866184235 G: 2.0131983757019043 (Real: [3.9881101787090301, 1.1478168989297544], Fake: [0.4706003931351006, 0.56432951749273874]) \n",
      "1000: D: 0.07969240099191666/0.11074899137020111 G: 2.802726984024048 (Real: [4.1164034307003021, 1.3332585979281273], Fake: [2.7175288861989975, 0.78567797556476349]) \n",
      "1200: D: 0.8352810144424438/0.36125344038009644 G: 1.0179462432861328 (Real: [4.1636496341228488, 1.14761223292501], Fake: [4.0020152807235716, 0.97445253552705058]) \n",
      "1400: D: 0.7911691665649414/0.4630472660064697 G: 0.7833588123321533 (Real: [3.94632781624794, 1.1761395137564206], Fake: [4.461441757678986, 1.3167211453605645]) \n",
      "1600: D: 1.3210893869400024/1.6782934665679932 G: 0.709025502204895 (Real: [4.0831651449203488, 1.1830239005878931], Fake: [5.159278402328491, 1.4243523430881748]) \n",
      "1800: D: 0.6430602073669434/0.49724265933036804 G: 0.7481811046600342 (Real: [3.9203891843557357, 1.1777001355179433], Fake: [5.2806966602802277, 1.3914968328231139]) \n",
      "2000: D: 0.6933594346046448/0.4200538396835327 G: 1.1439385414123535 (Real: [4.0453260093927383, 1.2400145583170412], Fake: [5.0002091455459592, 1.3377745845736819]) \n",
      "2200: D: 0.3964788615703583/0.6263415813446045 G: 0.8966724276542664 (Real: [3.9807418739795684, 1.2609376821606664], Fake: [4.7009579253196714, 1.1768209781756382]) \n",
      "2400: D: 0.7218139171600342/0.7462749481201172 G: 0.6727696061134338 (Real: [4.1464955687522886, 1.108467095174424], Fake: [4.0218521296978, 1.0693114237719399]) \n",
      "2600: D: 0.8725877404212952/0.8272190093994141 G: 0.42147406935691833 (Real: [4.1793558406829838, 1.2398678023901952], Fake: [3.2624221581220625, 1.1132383791641933]) \n",
      "2800: D: 0.7660529017448425/0.6052319407463074 G: 0.5680129528045654 (Real: [3.9720333340391516, 1.2716533378237103], Fake: [3.2760582351684571, 1.1538729953967035]) \n",
      "3000: D: 0.8039606809616089/0.7868324518203735 G: 0.706142246723175 (Real: [3.8561244648694992, 1.3212237377426668], Fake: [3.5385495138168337, 1.3911204199671559]) \n",
      "3200: D: 0.7285094857215881/0.7329800724983215 G: 0.6867119073867798 (Real: [4.117127109766006, 1.2962183764630075], Fake: [4.5130994498729704, 1.3520163965247241]) \n",
      "3400: D: 0.8197716474533081/0.5839866995811462 G: 0.8455235362052917 (Real: [4.1205427469313145, 1.251719329612589], Fake: [4.8948935484886169, 1.1771691158980753]) \n",
      "3600: D: 0.4925060570240021/0.6656795144081116 G: 0.666239857673645 (Real: [3.9899934211373331, 1.2053795380289754], Fake: [4.476174130439758, 1.3018881972788661]) \n",
      "3800: D: 0.7988147139549255/0.7198728919029236 G: 0.47295141220092773 (Real: [4.1169519567489621, 1.1134611887521251], Fake: [3.6617861264944076, 1.2410732873985284]) \n",
      "4000: D: 0.640074610710144/0.8149685859680176 G: 0.6788008809089661 (Real: [3.8823311316967009, 1.3067733774577224], Fake: [3.661630413532257, 1.0357265158558941]) \n",
      "4200: D: 0.4229132831096649/1.1475478410720825 G: 0.4374082386493683 (Real: [4.0148584043979643, 1.1469401479392729], Fake: [4.4662085294723513, 1.0841496820886347]) \n",
      "4400: D: 0.4939083456993103/0.4005239009857178 G: 0.8284751176834106 (Real: [3.9024937486648561, 1.2953859490890913], Fake: [4.2848376452922823, 1.6751040552265701]) \n",
      "4600: D: 0.8938887119293213/0.8820444345474243 G: 0.952076256275177 (Real: [4.0129896754026415, 1.1270574439232424], Fake: [3.9363709592819216, 1.2591194165532913]) \n",
      "4800: D: 0.7205766439437866/0.7649365663528442 G: 0.5167291164398193 (Real: [4.1009278464317322, 1.2092042919792845], Fake: [3.7822515761852262, 1.0539224435265098]) \n",
      "5000: D: 0.5943647027015686/0.8157535195350647 G: 0.5142440795898438 (Real: [3.8762651360034943, 1.2407332458369003], Fake: [3.7906301748752593, 1.1638507059310514]) \n",
      "5200: D: 0.7817140221595764/0.7187197804450989 G: 0.6842305064201355 (Real: [4.0788146567344663, 1.3798193241413561], Fake: [4.5414088141918185, 1.1721460419063714]) \n",
      "5400: D: 0.5452063083648682/0.5924292206764221 G: 0.9975625276565552 (Real: [3.9171034801006317, 1.173011215995825], Fake: [4.2422916948795315, 1.3490853240233018]) \n",
      "5600: D: 0.45687127113342285/0.61395263671875 G: 0.6694802045822144 (Real: [3.8956660495698454, 1.1515400663198905], Fake: [3.5034911769628523, 1.4154891545892221]) \n",
      "5800: D: 0.6468559503555298/0.6380376219749451 G: 0.7186404466629028 (Real: [4.0763206326961514, 1.2518538375281176], Fake: [3.529119848012924, 1.2634870453763385]) \n",
      "6000: D: 0.9056105613708496/0.7620715498924255 G: 0.6069908142089844 (Real: [3.7879409331083296, 1.2446812535097234], Fake: [4.0395285272598267, 1.3390542943578287]) \n",
      "6200: D: 0.7414039969444275/0.5317833423614502 G: 0.6656675934791565 (Real: [4.0261833083629606, 1.1488435219217021], Fake: [3.8620922636985777, 1.5057754409800679]) \n",
      "6400: D: 0.8256060481071472/0.9839518070220947 G: 0.5621706247329712 (Real: [3.8564438295364378, 1.0342730446807078], Fake: [3.5779897856712339, 1.3418454505923458]) \n",
      "6600: D: 0.7503363490104675/0.525387167930603 G: 0.8578969240188599 (Real: [3.9845677793025969, 1.3369737121333294], Fake: [4.1647372198104859, 1.1869155633507882]) \n",
      "6800: D: 0.7098279595375061/0.6468735933303833 G: 0.694061815738678 (Real: [3.8126447558403016, 1.1731527965568549], Fake: [4.0801407468318942, 1.1987012095279543]) \n",
      "7000: D: 0.8298834562301636/0.512596845626831 G: 0.6038320660591125 (Real: [4.0685278677940371, 1.2349809205306672], Fake: [3.8250483989715578, 1.1913008549533115]) \n",
      "7200: D: 0.37350916862487793/0.5950356125831604 G: 0.6940699219703674 (Real: [4.0688350331783294, 1.1614069103164226], Fake: [4.0677708578109737, 1.2118584299310604]) \n",
      "7400: D: 0.9167899489402771/0.7004644870758057 G: 0.5501546263694763 (Real: [3.9852466183900832, 1.1680547450331464], Fake: [3.9605405473709108, 1.3304594300686725]) \n",
      "7600: D: 0.9495047330856323/0.4028846323490143 G: 0.9464572668075562 (Real: [3.9757262122631074, 1.2744832467403973], Fake: [3.8913134133815763, 1.3078516231601582]) \n",
      "7800: D: 0.5323051810264587/0.5202748775482178 G: 0.7416332364082336 (Real: [4.2854988890886307, 1.1759707591376674], Fake: [4.3329393696784972, 1.2310722176792148]) \n",
      "8000: D: 0.6678231358528137/0.7666251063346863 G: 0.6683957576751709 (Real: [4.0330115145444871, 1.2621963000836995], Fake: [3.9398264324665071, 1.0707811930331228]) \n",
      "8200: D: 0.45288264751434326/0.6004951000213623 G: 0.718016505241394 (Real: [3.8691227981448173, 1.2396724703053792], Fake: [4.0894491326808931, 1.149847092402648]) \n",
      "8400: D: 0.6491543054580688/0.5122874975204468 G: 0.9144439697265625 (Real: [4.0601747536659243, 1.0917543634304059], Fake: [4.0306886672973636, 1.1844472635847536]) \n",
      "8600: D: 0.5861944556236267/0.6560963988304138 G: 0.8251690864562988 (Real: [4.0099662470817563, 1.2994289491032736], Fake: [3.9957278108596803, 1.2220803664975481]) \n",
      "8800: D: 0.6011114120483398/0.5991806983947754 G: 0.48587560653686523 (Real: [4.0947081404924397, 1.3621678635635404], Fake: [4.019775514602661, 1.0875790180423304]) \n",
      "9000: D: 0.9343106150627136/0.5476986169815063 G: 0.7706409692764282 (Real: [4.0726209855079647, 1.0340165025101289], Fake: [4.1232624065876005, 1.1151240274200991]) \n",
      "9200: D: 0.5679290294647217/0.6054483652114868 G: 0.7577130794525146 (Real: [3.8706961804628373, 1.3466770202742417], Fake: [4.1574119037389758, 1.1999397416007851]) \n",
      "9400: D: 0.6334500908851624/0.8204431533813477 G: 0.7319775819778442 (Real: [3.732180100083351, 1.2567711837797348], Fake: [4.0444530808925627, 1.255035341797047]) \n",
      "9600: D: 0.5915340185165405/0.4737809896469116 G: 0.9412864446640015 (Real: [3.8025717592239379, 1.2268008198978801], Fake: [3.974016003012657, 1.3033040695263969]) \n",
      "9800: D: 0.4039154350757599/0.674621045589447 G: 0.8087462782859802 (Real: [4.0118605053424838, 1.2491535856053564], Fake: [3.9057284653186799, 1.439137352183727]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.4605080187320709/0.6545906066894531 G: 0.7222508788108826 (Real: [3.9682945823669433, 1.2388837634512304], Fake: [4.125325989127159, 1.3054842383967098]) \n",
      "10200: D: 0.6009887456893921/0.5211098194122314 G: 0.8292682766914368 (Real: [4.1526535423845052, 1.1840650140518765], Fake: [3.8940234857797624, 1.3016225625412801]) \n",
      "10400: D: 0.623485803604126/0.7103880047798157 G: 0.5747432708740234 (Real: [3.8938691937923431, 1.2831633272956378], Fake: [3.994795436859131, 1.3455326163296097]) \n",
      "10600: D: 0.7250586748123169/0.7088103890419006 G: 0.9190853238105774 (Real: [3.6585712096095087, 1.2236852592118925], Fake: [4.0267258596420286, 1.3601611757301317]) \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def train_GAN(num_epochs):\n",
    "    '''\n",
    "    '''\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size)).cuda()\n",
    "        \n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones(1).cuda()))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size)).cuda()\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)).cuda()).cuda()  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size)).cuda()\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones(1)).cuda())  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
