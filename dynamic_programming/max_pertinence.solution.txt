Spoiler alert: the question is a typical 'dynamic programming' problem, which can be resolved in linear complexity O(n).

The strategy to resolve the problem can be formulated as 'divide-and-conquer', in the sense that we could divide the original problem into a set of "subproblems", and the subproblems are of the same nature of the original problem but in smaller scale. 

"Recursively", we could further divide the subproblems in the same manner, until we reach the bottom case where we can obtain the solution for the finest subproblem without any dependency. 

Then with the result for the bottom case, we trace back step by step to get the solution for the original problem.

Different from the naive recursive algorithm, dynamic programming keeps the "intermediate" results so that they can be reused later, instead of being re-calculated. It trades some minor memory to gain the efficiency of calculation. 

More specifically, here we explain, how we can apply the above "dynamic programming" algorithm into the question we have.

The question is to find out the maximum pertinence we can obtain, by walking through a list of offers, at a pace of maximum 5 offers each time. 

Since one of the goals is to reach the end of the offers, we could start to construct the solution reversely, by taking the last offer at first. 

e.g.  offers = [v1, v2, v3, v4, v5, v6, v7, v8, v9]

The final solution must contains the last offer v9.
And there are five paths that we can reach the last offer, namely via v4, v5, v6, v7, v8.

If we define the maximum pertinence we could get with the initial 9 offers, as P9,
then   P9 = v9 + max{P4, P5, P6, P7, P8}, i.e. the final solution is the maximum value we could get from one of the previous offers, plus the final offer, where  P4:  is the maximum pertinence we could get from the list of offers [v1, v2, v3, v4], so on so forth for other variables P5, P6, P7, P8. 

Applied above notation, one can deduct the variable P8 (i.e. the maximum pertinence we could get, when the final offer is v8) as follows:
P8 = v8 + max{P3, P4, P5, P6, P7}

And we have the bottom case P1 = v1. 

We could see that, the final solution depends on the solutions of sub-problems, and there are overlapping of variables between subproblems, which in all, implies that we could apply the "dynamic programming" algorithm as we stated above.

Given the above formulas, it would be easy to implement the algorithm in any programming language. Here is one example in Python. 

======================================================
def max_pertinence(offers):
    '''
        Calculate the maximum pertience, with dynamic programming algorithm.
    '''
    # the list to keep the intermediate and final solutions.
    dp_max = [0]*len(offers)
    
    for idx, offer in enumerate(offers):
        # retrieve the previous 5 candidates
        candidates = (dp_max[:(idx+1)])[-5:]
        
        # get the offer from the best candidate
        dp_max[idx] = offer + max(candidates)
    
    return dp_max


offers = [1, 0, -1, 3, -1, -2]

max_pertinence(offers)    

======================================================


As one can see from the above algorithm, we have a linear time complexity O(5N) ~ O(N), where N is the number of offers. In detail, there is one loop, and at each step of loop, we have a maximum 5 elements to look at.

And the space complexity of the algorithm is O(N) which corresponds to the memory we use to store the intermediate results of dynamic programming. Actually, we could further reduce the space complexity to constant O(1), by keeping only the relevant intermediate results, i.e. a sliding window of size 5, where we only need to keep the maximum pertinence values for the previous 5 subproblems. For the simplicity and clarity of the algorithm, here we keep all the intermediate results. 

